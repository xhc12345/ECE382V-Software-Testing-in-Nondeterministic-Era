prompts:
  test_fun_fact: |
    Tell me a short fun fact about space.
    Preferably, it's about the Solar System.

  test_json_response: |
    Compare Python, Lua, Java, C#, Golang. Respond as a JSON in the following format listed below. Do not add any decorators or comments, only give JSON response as plain text.
    {
      "winner": <language name>,
      "reason": <explain why winner is this language>
      "languages": [
        {
          "name":<name of language>,
          "description":<description of language>,
          "year_created":<which year it was created>,
          "compatibility":<how compatible is the language across different platforms>,
          "speed":<describe how fast is the langauge run>
        }
      ]
    }

  test_check_previous_conversation: |
    What was my previous question(s)?

  praise_the_LLM: |
    You are a flaky test detection tool.

  flaky_detect_1: |
    In software testing, a flaky test is a test that will output different results on different runs   despite testing the same source code.
    The given test (suite) given below is composed of one or more tests that may or may not be flaky.
    Analyze each test to determine if there are any flaky behaviors, and identify which lines have what kind of flaky behavior.
    For categorization, use to the following rules:
      OD = Order-Dependent flaky tests as defined in iDFlakies
      OD-Brit = Order-Dependent Brittle tests as defined in iFixFlakies
      OD-Vic = Order-Dependent Victim tests as defined in iFixFlakies
      ID = Implementation-Dependent Tests found by Nondex
      ID-HtF = Implementation-Dependent tests that are hard to fix.
      NIO = Non-Idempotent-Outcome Tests as defined in ICSE’22 work. Tests that pass in the first run but fail in the second.
      NOD = Non-Deterministic tests
      NDOD = Non-Deterministic Order-Dependent tests that fail non-deterministically but with significantly different failure rates in different orders as defined in our ISSRE’20 work
      NDOI = Non-Deterministic Order-Independent tests that fail non-deterministically but similar failure rates in all orders as defined in our ISSRE’20 work
      UD = Unknown Dependency tests that pass and fail in a test suite or in isolation
      OSD = Operating System Dependent tests that pass and fail depending on the operating system
      TZD = Tests that fail in machines on different time zones, usually failing time-related assertions
    Respond in a valid JSON format following the rules below. Do not add any decorators or comments, only give JSON response as plain text, do not wrap it in code blocks.
    {
      "flakies": [
        {
          "name":<name of the test that is flaky>,
          "flakyOcurrences":[
            {
              "lineNumber": <from which line to which line does this flaky behavior occurred>,
              "lineCode": <the code that contains this flaky behavior. This code need to be converted to a valid JSON string that can be placed in a JSON object>,
              "type": <type of flaky behavior for this>,
              "Category": <abbreviation of the categorization best fit for this test>,
              "explain": <1-3 sentences explain why this is flaky>
            }
          ]
        }
      ],
      "notFlakies": [
        <name of the test that is NOT flaky>,
      ]
    }

  flaky_detect_2: |
    For the previous question, I also asked 2 other large langauge models (LLM) for their analysis with the same prompt. I attached their responses in the end.
    Compare your response to their responses and analyze if you can make improvements or point out if they did analyzed incorrectly.
    Respond as a JSON in the following format listed below. Do not add any decorators or comments, only give JSON response as plain text, do not wrap it in code blocks.
    {
      "flakies": [
        {
          "name":<name of the test that is flaky>,
          "correctlyAnalyzed":[<a list here of the names of all the models that flagged this test with the correct type in the previous question. If you got this right in the last question, include your model name here too>],
          "flakyOcurrences":[
            {
              "lineNumber": <from which line to which line does this flaky behavior occurred>,
              "lineCode": <the code that contains this flaky behavior. This code need to be converted to a valid JSON string that can be placed in a JSON object>,
              "type": <type of flaky behavior for this>,
              "Category": <abbreviation of the categorization (using rules I gave you before) best fit for this test>,
              "explain": <1-3 sentences explain why this is flaky>
            }
          ]
        }
      ],
      "notFlakies": [
        <name of the test that is NOT flaky>,
      ]
    }

  prompt2: |
    This is the second prompt.
    Remember to include all important details here, and feel free
    to use line breaks for readability.

  prompt3: |
    This is the third prompt.
    You can even include special characters like "quotes", $dollar signs,
    and line breaks to format your message effectively.
